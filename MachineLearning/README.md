# About Machine Learning

衡量一个模型泛化误差的两个方面：  
- 偏差：
指的是模型预测的期望值与真实值之间的差；
用于描述模型的拟合能力；
偏差通常是由于我们对学习算法做了错误的假设，或者模型的复杂度不够；
- 方差：
指的是模型预测的期望值与预测值之间的差平方和；
用于描述模型的稳定性。
通常是由于模型的复杂度相对于训练集过高导致的；

- 因此深度学习的核心工作之一就是研究如何降低模型的泛化误差，这类方法统称为正则化方法。

偏差与方差的权衡
- 当训练不足时，模型的拟合能力不够（数据的扰动不足以使模型产生显著的变化），此时偏差主导模型的泛化误差；
- 随着训练的进行，模型的拟合能力增强（模型能够学习数据发生的扰动），此时方差逐渐主导模型的泛化误差；

监督学习的任务是学习一个模型，对给定的输入预测相应的输出
这个模型的一般形式为一个决策函数或一个条件概率分布（后验概率）：

监督学习模型可分为生成模型与判别模型

- 判别模型
> 
直接学习决策函数或者条件概率分布
直接面对预测，往往学习的准确率更高
由于直接学习 P(Y|X) 或 f(X)，可以对数据进行各种程度的抽象，定义特征并使用特征，以简化学习过程
不能反映训练数据本身的特性
常见模型：K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、最大熵模型、SVM、提升方法、条件随机场

- 生成模型
> 
学习的是联合概率分布P(X,Y)，然后根据条件概率公式计算 P(Y|X)
可以还原出联合概率分布 P(X,Y)，判别方法不能
学习收敛速度更快——即当样本容量增加时，学到的模型可以更快地收敛到真实模型
当存在“隐变量”时，只能使用生成模型
学习和计算过程比较复杂
由生成模型可以得到判别模型，但由判别模型得不到生成模型。
常见模型：朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场

- 隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”

- 条件概率（似然概率）
> 
一个事件发生后另一个事件发生的概率。
一般的形式为 P(X|Y)，表示 y 发生的条件下 x 发生的概率。
有时为了区分一般意义上的条件概率，也称似然概率

- 先验概率
> 
事件发生前的预判概率
可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。
一般都是单独事件发生的概率，如 P(A)、P(B)。

- 后验概率
> 
基于先验概率求得的反向条件概率，形式上与条件概率相同（若 P(X|Y) 为正向，则 P(Y|X) 为反向）
贝叶斯公式


超参数的选择
Grid Search：网格搜索；在高维空间中对一定区域进行遍历
Random Search：在高维空间中随机选择若干超参数
- 余弦距离
- 欧式距离
- 曼哈顿距离


- https://blog.csdn.net/weixin_41108334/article/details/86499638

### 基础
>
- k-近邻算法




### 决策树




### 基于概率论的分类方法：朴素贝叶斯




### Logistic回归


### 支持向量机


### 利用AdaBoost元算法提高分类性能




### 预测数值类型据：回归



### 树回归


## 无监督学习

### 利用K-均值聚类算法对未标注的数据分组

### 使用Apriori算法进行关联分析


### 使用GP-growth算法来搞笑发现频繁项集


